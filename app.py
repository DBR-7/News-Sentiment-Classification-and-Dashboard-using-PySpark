# -*- coding: utf-8 -*-
"""News_Streaming.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1owbwCo2NX1fKEb3x4lueqm3TF_ICHXl2
"""

import streamlit as st
import pandas as pd
import requests
from pyspark.sql import SparkSession
from pyspark.ml import Pipeline
from pyspark.ml.feature import Tokenizer, HashingTF, IDF
from pyspark.ml.classification import LogisticRegression
from pyspark.ml.evaluation import MulticlassClassificationEvaluator
from nltk.sentiment.vader import SentimentIntensityAnalyzer
import nltk
import altair as alt
import time

# --- INITIAL SETUP ---
st.set_page_config(
    page_title="PySpark News Sentiment Dashboard",
    page_icon="ðŸ“°",
    layout="wide"
)

# Download VADER lexicon during the build process
try:
    nltk.data.find('sentiment/vader_lexicon.zip')
except LookupError:
    nltk.download('vader_lexicon')

# --- SPARK SESSION ---
@st.cache_resource
def get_spark():
    """Creates and returns a Spark Session."""
    return SparkSession.builder \
        .appName("NewsSentimentDashboard") \
        .master("local[*]") \
        .config("spark.driver.memory", "4g") \
        .config("spark.ui.showConsoleProgress", "false") \
        .getOrCreate()

spark = get_spark()

# --- NEWS API & DATA LABELING ---
# Securely access the API key using Streamlit's secrets management.
# This key will be set in the Streamlit Cloud dashboard, not in a file.
try:
    NEWS_API_KEY = st.secrets["NEWS_API_KEY"]
except KeyError:
    st.error("NEWS_API_KEY not found in secrets. Please set it in your Streamlit Cloud app settings.")
    st.stop()


def fetch_news(topic, page_size=10):
    """Fetches news articles and returns a Pandas DataFrame."""
    url = f"https://newsapi.org/v2/everything?q={topic}&pageSize={page_size}&sortBy=publishedAt&apiKey={NEWS_API_KEY}"
    try:
        r = requests.get(url)
        r.raise_for_status()
        articles = r.json().get("articles", [])
        valid_articles = [a for a in articles if a.get("title")]
        return pd.DataFrame([{"title": a["title"]} for a in valid_articles])
    except requests.exceptions.RequestException as e:
        st.error(f"Error fetching news: {e}")
        return None

def label_sentiment_vader(df_pd):
    """Labels a DataFrame with sentiment using VADER."""
    sia = SentimentIntensityAnalyzer()

    def classify_title(title):
        score = sia.polarity_scores(title)["compound"]
        if score > 0.05:
            return "Positive"
        elif score < -0.05:
            return "Negative"
        else:
            return "Neutral"

    df_pd["sentiment"] = df_pd["title"].apply(classify_title)
    label_map = {"Positive": 2.0, "Neutral": 1.0, "Negative": 0.0}
    df_pd["label"] = df_pd["sentiment"].map(label_map)
    return df_pd

# --- UI COMPONENTS ---
st.title("ðŸ“° PySpark News Sentiment Dashboard")
st.markdown("""
This dashboard fetches live news articles, trains a PySpark ML model, and then
uses the model to predict sentiment on new articles in a simulated stream.
""")

with st.sidebar:
    st.header("âš™ï¸ Controls")
    topic = st.text_input("Enter a News Topic", "finance")
    mode = st.radio("Select Mode", ["Bootstrap", "Predict"])
    num_articles = st.slider("Number of Articles to Fetch", 5, 50, 10)
    run_button = st.button("Run Analysis")

# --- MAIN LOGIC ---
if run_button:
    with st.spinner(f"Fetching {num_articles} articles about '{topic}'..."):
        df_pd = fetch_news(topic, num_articles)

    if df_pd is None or df_pd.empty:
        st.warning("Could not fetch any news articles. Please try a different topic.")
    else:
        if mode == "Bootstrap":
            st.header("ðŸ› ï¸ Bootstrap Mode: Training Model")
            with st.spinner("Labeling data and training PySpark model..."):
                df_pd_labeled = label_sentiment_vader(df_pd)
                df_spark = spark.createDataFrame(df_pd_labeled)
                tokenizer = Tokenizer(inputCol="title", outputCol="words")
                hashingTF = HashingTF(inputCol="words", outputCol="rawFeatures", numFeatures=2000)
                idf = IDF(inputCol="rawFeatures", outputCol="features")
                lr = LogisticRegression(featuresCol="features", labelCol="label", maxIter=10, regParam=0.001)
                pipeline = Pipeline(stages=[tokenizer, hashingTF, idf, lr])
                model = pipeline.fit(df_spark)
                predictions = model.transform(df_spark)
                evaluator = MulticlassClassificationEvaluator(labelCol="label", predictionCol="prediction", metricName="accuracy")
                train_accuracy = evaluator.evaluate(predictions)
                st.session_state['sentiment_model'] = model
                st.success("âœ… Model trained successfully!")
                st.metric(label="Training Accuracy", value=f"{train_accuracy:.2%}")
            st.subheader("Bootstrap Training Data")
            st.dataframe(df_pd_labeled[["title", "sentiment"]], use_container_width=True)

        elif mode == "Predict":
            st.header("ðŸ”® Predict Mode: Analyzing New Articles")
            if 'sentiment_model' not in st.session_state:
                st.error("Model not found! Please run in 'Bootstrap' mode first.")
            else:
                with st.spinner("Applying trained model..."):
                    model = st.session_state['sentiment_model']
                    df_spark_new = spark.createDataFrame(df_pd)
                    predictions = model.transform(df_spark_new)
                    predictions_df = predictions.select("title", "prediction").toPandas()
                    label_map_reverse = {2.0: "Positive", 1.0: "Neutral", 0.0: "Negative"}
                    predictions_df["sentiment"] = predictions_df["prediction"].map(label_map_reverse)
                st.subheader("Sentiment Predictions")
                st.dataframe(predictions_df[["title", "sentiment"]], use_container_width=True)
                col1, col2 = st.columns([0.6, 0.4])
                with col1:
                    st.subheader("ðŸ“Š Sentiment Distribution")
                    chart_data = predictions_df.groupby("sentiment").size().reset_index(name='count')
                    chart = alt.Chart(chart_data).mark_bar().encode(
                        x=alt.X('sentiment', axis=alt.Axis(title='Sentiment')),
                        y=alt.Y('count', axis=alt.Axis(title='Number of Articles')),
                        color='sentiment',
                        tooltip=['sentiment', 'count']
                    ).properties(title='Distribution of Predicted News Sentiment')
                    st.altair_chart(chart, use_container_width=True)
                with col2:
                    st.subheader("ðŸ“¡ Streaming Simulation")
                    placeholder = st.empty()
                    for idx, row in predictions_df.iterrows():
                        sentiment_emoji = {"Positive": "ðŸ˜„", "Neutral": "ðŸ˜", "Negative": "ðŸ˜ "}
                        with placeholder.container():
                            st.markdown(f"**Article:** {row['title']}")
                            st.markdown(f"**Predicted Sentiment:** {row['sentiment']} {sentiment_emoji.get(row['sentiment'], '')}")
                            st.progress((idx + 1) / len(predictions_df))
                        time.sleep(0.7)
                st.success("âœ… Prediction and analysis complete!")
else:
    st.info("Adjust the controls in the sidebar and click 'Run Analysis' to begin.")